{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cv2\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import flatten\n",
    "from torch.nn import Module, Conv2d, Linear, MaxPool2d, ReLU, Flatten, Sequential\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import lightning as pl\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metadata():\n",
    "    metadata = pd.DataFrame(columns=[\"image_name\", \"path\", \"label\"])\n",
    "    for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "        for filename in filenames:\n",
    "            data = [filename, os.path.join(dirname, filename), 0 if os.path.basename(os.path.normpath(dirname)).strip() == \"no\" else 1]\n",
    "            metadata.loc[len(metadata)] = data\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainMRIDataset(Dataset):\n",
    "    def __init__(self, metadata=None, image_size=None):\n",
    "        super().__init__()\n",
    "        if metadata:\n",
    "            self.metadata = pd.read_csv(csv_file)\n",
    "        else:\n",
    "            self.metadata = create_metadata()\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.metadata[\"path\"][idx]\n",
    "        image_label = self.metadata[\"label\"][idx]\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if self.image_size:\n",
    "            image = cv2.resize(image, (self.image_size, self.image_size))\n",
    "        image = np.asarray(image)\n",
    "        image = ToTensor()(image[ :, :, np.newaxis])\n",
    "        \n",
    "        return {\n",
    "            \"image\": image,\n",
    "            \"label\": image_label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, num_channels=1, num_classes=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = Sequential(\n",
    "            Conv2d(in_channels=num_channels, out_channels=16, kernel_size=(3, 3), padding='same'),\n",
    "            ReLU(),\n",
    "            MaxPool2d(kernel_size=(2, 2)),\n",
    "            \n",
    "            Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding='same'),\n",
    "            ReLU(),\n",
    "            MaxPool2d(kernel_size=(2, 2)),\n",
    "            Flatten(),\n",
    "            Linear(in_features=65536, out_features=128),\n",
    "            ReLU(),\n",
    "            Linear(in_features=128, out_features=num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        image_batch, label_batch = batch[\"image\"], batch[\"label\"]\n",
    "        predict = self.model(image_batch)\n",
    "        train_loss = cross_entropy(predict, label_batch)\n",
    "        self.log(\"train_loss\", train_loss)\n",
    "        return train_loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        image_batch, label_batch = batch[\"image\"], batch[\"label\"]\n",
    "        predict = self.model(image_batch)\n",
    "        val_loss = cross_entropy(predict, label_batch)\n",
    "        self.log(\"val_loss\", val_loss)\n",
    "        return val_loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        image_batch, label_batch = batch[\"image\"], batch[\"label\"]\n",
    "        predict = self.model(image_batch)\n",
    "        test_loss = cross_entropy(predict, label_batch)\n",
    "        self.log(\"test_loss\", test_loss)\n",
    "        return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(dataset):\n",
    "    \n",
    "    label_list = [dataset[idx][\"label\"] for idx in range(len(dataset))]\n",
    "    train_idx, valid_and_test_idx = train_test_split(range(len(dataset)), test_size=0.4, stratify=label_list)\n",
    "    \n",
    "    valid_and_test_label = [label_list[idx] for idx in valid_and_test_idx]\n",
    "    val_idx, test_idx = train_test_split(valid_and_test_idx, test_size=0.5, stratify=valid_and_test_label)\n",
    "    \n",
    "    return train_idx, val_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(dataset, batch_size=64):\n",
    "    \n",
    "    train_idx, val_idx, test_idx = train_val_test_split(dataset)\n",
    "    \n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_idx, drop_last=True)\n",
    "    val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_idx, drop_last=True)\n",
    "    test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_idx, drop_last=True)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BrainMRIDataset(image_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader = prepare_dataloader(dataset, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(logger=TensorBoardLogger(save_dir=\"logs/\"), callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\")])\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_CHAEKPOINT = \"/kaggle/working/logs/lightning_logs/version_0/checkpoints/epoch=12-step=52.ckpt\"\n",
    "model = Model.load_from_checkpoint(PATH_TO_CHAEKPOINT)\n",
    "trainer.test(model, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
